# -*- coding: utf-8 -*-
"""House_Price_Prediction-AF_20_16850

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z_Qd25u_fodv2Zz1mqKu190NkI33Z2eV

AF-20-16850

AR-102685

D.A.T.Thuvarangan

## **Data Inspection and Preprocessing**
"""

from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir("/content/drive/MyDrive/Assignment_ML/Regression")

"""locating prediction data details present file"""

import pandas as pd

housingdata = pd.read_csv("ParisHousing.csv")
housingdata.head()

"""showcasing the data set. according to the data set above, there are no string based data variables there inorder to convert to int using encoding method and we don't need to drop string based data."""

housingdata.shape

housingdata.info()

"""info about data type of each variables"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.pairplot(housingdata)
plt.show()

corr_matrix = housingdata.corr()

fig, ax = plt.subplots(figsize=(22,12))
sns.heatmap(corr_matrix, annot=True, cmap = 'coolwarm', ax=ax)
plt.show()

from sklearn.model_selection import train_test_split

features = housingdata.columns.drop(['price'])
# Remove independent unwanted variables if any (e.g., cityCode, made)

"""In the dataset there is no uwanted variables present. the price is the dependent variable. so were drop that from our dataset."""

X = housingdata[features]
y = housingdata['price']

"""## **train-test split to prepare the data for modeling**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=55)

"""seperating test and train data as x and y

## **Evaluate The Performance of 3 Regression Machine Learning Algorithms**

The price of houses is a continuous variable. Regression algorithms are a perfect fit for this kind of prediction problem because they are made to predict continuous outcomes based on input features. Standard measures like mean absolute error (MAE) and mean squared error (MSE) can be used to evaluate regression algorithms. By offering measurable evaluations of model performance, these metrics make it possible to compare various regression models and adjust the model's parameters.

## **1.Linear Regression**
"""

from sklearn.linear_model import LinearRegression
import numpy as np

"""selected as the first regression ML algorithm to evaluate the performance."""

lr = LinearRegression()

lr.fit(X_train, y_train)

y_pred_lr = lr.predict(X_test)

# Define a threshold for accuracy calculation
threshold = 10000

"""This threshold will be used to determine whether the predictions made by the model are accurate or not."""

# Calculate the accuracy score based on the threshold
accuracy_score = np.mean(np.abs(y_pred_lr- y_test) <= threshold)
print("Accuracy Score (Threshold={}): {:.2f}%".format(threshold, accuracy_score * 100))

"""The purpose of calculating the accuracy score is to evaluate how well the machine learning model performs in making predictions compared to the actual target values.


The accuracy score is calculated using the following steps:

* Subtracting the predicted values (y_pred_lr) from the true values (y_test).
* Taking the absolute difference between the predicted and true values.
* Checking if the absolute difference is less than or equal to the defined threshold.
* Taking the mean of these comparisons to obtain the accuracy score.
"""

lr.coef_

#Performance Evaluation
from sklearn.metrics import r2_score, mean_absolute_error,mean_squared_error
def regression_metrices(actual,predicted):
    r2_score_value = r2_score(actual,predicted)
    mae_value = mean_absolute_error(actual,predicted)
    mse_value = mean_squared_error(actual,predicted,squared=False)
    print(f"R2 Score: {r2_score_value:.2f}")
    print(f"Mean Absolute Error: {mae_value:.2f}")
    print(f"Mean Squared Error: {mae_value:.2f}")

"""**Performance Evaluation using Matrics**

-R-squared indicates how well the regression model fits the data.(closer to 1-better fit,closer to 0-poor fit)

-mean absolute error gives avarage magnitude of errors(absolute error between the predicted values and the actual values).

-mean squared error gives the average of squared errors.
"""

regression_metrices(y_pred_lr,y_test)

"""performance evaluation of the model on the test set"""

from yellowbrick.regressor import residuals_plot
from yellowbrick.regressor import PredictionError

viz_lm = residuals_plot(lr, X_train, y_train, X_test, y_test, hist=True, qqplot=False)

"""A residual plot is a scatterplot that displays the residuals on the vertical axis and the independent variable on the horizontal axis. Residual plots help us to determine whether a linear model is appropriate in modeling the given data.

Interpret the plot

1. residual=0
2. the points are scattered randomly around the residual=0 line. We can conclude that this linear regession model is appropriate for modeling this data.
"""

pred_viz_lm = PredictionError(lr)

pred_viz_lm.fit(X_train, y_train)
pred_viz_lm.score(X_test, y_test)
pred_viz_lm.show()

"""## **2.Decision Tree**

selected as the 2nd regression ML algorithm to evaluate the performance.
"""

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.metrics import accuracy_score

"""selected as the 2nd regression ML algorithm to evaluate the performance on house price prediction.

Split the dataset into training and testing sets (80% training, 20% testing)
"""

dt_regressor = DecisionTreeRegressor(random_state=55)
dt_regressor.fit(X_train, y_train)

y_pred_dt_regressor = dt_regressor.predict(X_test)

threshold = 10000  # Example threshold for accuracy calculation

# Calculate the accuracy score based on the threshold
accuracy_score = np.mean(np.abs(y_pred_dt_regressor- y_test) <= threshold)
print("Accuracy Score (Threshold={}): {:.2f}%".format(threshold, accuracy_score * 100))

regression_metrices(y_pred_dt_regressor,y_test)

# Update feature names based on the current dataset
feature_names = X.columns.tolist()

# Re-plot residuals using updated feature names
viz_rf = residuals_plot(dt_regressor, X_train, y_train, X_test, y_test, feature_names=feature_names, hist=True, qqplot=False)

pred_viz_rf = PredictionError(dt_regressor)

pred_viz_rf.fit(X_train, y_train)
pred_viz_rf.score(X_test, y_test)
pred_viz_rf.show()

from yellowbrick.model_selection import FeatureImportances

viz = FeatureImportances(dt_regressor)
viz.fit(X_train, y_train)
viz.show()

"""## **3.Random Forest**

selected as the 3rd regression ML algorithm to evaluate the performance.
"""

from sklearn.ensemble import RandomForestRegressor
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)  # we can adjust the number of trees (n_estimators)
rf_regressor.fit(X_train, y_train)

y_pred_rf_regg = rf_regressor.predict(X_test)

# Define a threshold for accuracy calculation
threshold = 10000

# Calculate the accuracy score based on the threshold
accuracy_score = np.mean(np.abs(y_pred_rf_regg - y_test) <= threshold)
print("Accuracy Score (Threshold={}): {:.2f}%".format(threshold, accuracy_score * 100))

regression_metrices(y_pred_rf_regg,y_test)

# Update feature names based on the current dataset
feature_names = X.columns.tolist()

# Re-plot residuals using updated feature names
viz_rf = residuals_plot(rf_regressor, X_train, y_train, X_test, y_test, feature_names=feature_names, hist=True, qqplot=False)

pred_viz_rf = PredictionError(rf_regressor)

pred_viz_rf.fit(X_train, y_train)
pred_viz_rf.score(X_test, y_test)
pred_viz_rf.show()

from yellowbrick.model_selection import FeatureImportances

viz = FeatureImportances(rf_regressor)
viz.fit(X_train, y_train)
viz.show()

"""-R-squared indicates how well the regression model fits the data.(closer to 1-better fit,closer to 0-poor fit)

-mean absolute error(MAE) gives avarage magnitude of errors(absolute error between the predicted values and the actual values).

-mean squared error(MSE) gives the average of squared errors.

-accuracy score helps in understanding the overall performance of the model and whether it meets the desired level of accuracy

1.   lower values of mse and mae indicate better performace an algorithm have.
2.   high value of r2 score indicate better fit of algorithm to provided dataset.
3.   High accuracy score is the perfect fit algorithm

these are the criterias (1,2,3) to select the most suitable algorithm to predict the price of houses.

**Linear** **Regression**
* Accuracy score-100.00%
* R2 score-1.00
* MAE-1490.74
* MSE-1490.74

**Decision Tree**
* Accuracy score-92.45%
* R2 score-1.00
* MAE-4353.44
* MSE-4353.44

**Random Forest**
* Accuracy score-99.25%
* R2 score-1.00
* MAE-3133.47
* MSE-3133.47



## **brief describtion of selected algorithm**

based on above, the lower values for MSE,MAE of an algorithm performs well. And the high value for R2 Score of an algorithm fits better to predict. The high accuracy score algorithm performs better. So, based on these, the linear regression ML algorithm have been selected as the most suitable algorithm because the accuracy score is greater than other 2 algorithms score. the R2 score is same for all 3 algorithms but the MAE and MSE is less than other 2 algorithms. so based on this, the linear regression is the most suitable one.

## **Challenges and Solutions**

Biggest challenge i have faced is the lack of module based knowledge. i don't know how to compare and select best algorithm by evaluating the performance of algorithms and i don't know how to show residuals plot.

to overcome from these challenges, I have refered some websites and asked my friends to complete the task.

here are some refered sites;

-https://medium.com/analytics-vidhya/mae-mse-rmse-coefficient-of-determination-adjusted-r-squared-which-metric-is-better-cd0326a5697e

https://study.com/skill/learn/how-to-interpret-a-residual-plot-explanation.html
"""